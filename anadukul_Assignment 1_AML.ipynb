{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A case study using iris dataset for KNN algorithm "
      ],
      "metadata": {
        "id": "bca1ZpDIsGD6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwk6dOM0E8Od",
        "outputId": "d5b88587-9242-4a51-c6d3-2583bdc4767d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions from the classifier:\n",
            "[0 1 2 0 2 0 1 1 0 1 1 0 0 0 0 0 0 0 2 0 2 1 1 1 0 2 1 1 2 0 2 0 2 1 2 2 1\n",
            " 1 1 2 2 0 2 2 0 1 0 2 2 0 1 1 0 0 1 1 1 1 2 1 2 0 0 1 1 2 0 2 1 0 2 2 1 2\n",
            " 2 0 0 2 1 1 2 0 1 1 0 1 1 2 2 1 0 2 0 2 0 0 1 2 2 1 2 2 0 1 1 0 2 2 2 1 2\n",
            " 2 2 0 0 1 0 2 2 1]\n",
            "Target values:\n",
            "[0 1 2 0 2 0 1 1 0 1 1 0 0 0 0 0 0 0 2 0 2 1 1 1 0 2 1 1 2 0 2 0 2 2 2 2 1\n",
            " 1 1 1 2 0 2 2 0 1 0 2 2 0 1 1 0 0 1 1 1 1 2 1 2 0 0 1 1 1 0 2 1 0 2 2 1 2\n",
            " 2 0 0 2 1 1 2 0 1 1 0 1 1 2 2 1 0 2 0 2 0 0 1 2 2 1 2 2 0 1 1 0 2 2 2 1 2\n",
            " 2 2 0 0 1 0 2 2 1]\n",
            "0.975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# import modules for this project\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load iris dataset\n",
        "iris = datasets.load_iris()\n",
        "data, labels = iris.data, iris.target\n",
        "\n",
        "# training testing split\n",
        "res = train_test_split(data, labels, \n",
        "                       train_size=0.8,\n",
        "                       test_size=0.2,\n",
        "                       random_state=12)\n",
        "train_data, test_data, train_labels, test_labels = res \n",
        "\n",
        "# Create and fit a nearest-neighbor classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# classifier \"out of the box\", no parameters\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train_data, train_labels) \n",
        "\n",
        "# print some interested metrics\n",
        "print(\"Predictions from the classifier:\")\n",
        "learn_data_predicted = knn.predict(train_data)\n",
        "print(learn_data_predicted)\n",
        "print(\"Target values:\")\n",
        "print(train_labels)\n",
        "print(accuracy_score(learn_data_predicted, train_labels))\n",
        "\n",
        "# re-do KNN using some specific parameters. \n",
        "knn2 = KNeighborsClassifier(algorithm='auto', \n",
        "                            leaf_size=30, \n",
        "                            metric='minkowski',\n",
        "                            p=2,         # p=2 is equivalent to euclidian distance\n",
        "                            metric_params=None, \n",
        "                            n_jobs=1, \n",
        "                            n_neighbors=5, \n",
        "                            weights='uniform')\n",
        "\n",
        "knn.fit(train_data, train_labels) \n",
        "test_data_predicted = knn.predict(test_data)\n",
        "accuracy_score(test_data_predicted, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this command to help with choice of paramters in the `KNeighborsClassifier` function. "
      ],
      "metadata": {
        "id": "EGCbBcE5v3Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(KNeighborsClassifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08A9rmgQ5RQW",
        "outputId": "5133df49-a36d-42d5-f8b6-36a295ba448d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class KNeighborsClassifier in module sklearn.neighbors._classification:\n",
            "\n",
            "class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n",
            " |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
            " |  \n",
            " |  Classifier implementing the k-nearest neighbors vote.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <classification>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  n_neighbors : int, default=5\n",
            " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
            " |  \n",
            " |  weights : {'uniform', 'distance'} or callable, default='uniform'\n",
            " |      Weight function used in prediction.  Possible values:\n",
            " |  \n",
            " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
            " |        are weighted equally.\n",
            " |      - 'distance' : weight points by the inverse of their distance.\n",
            " |        in this case, closer neighbors of a query point will have a\n",
            " |        greater influence than neighbors which are further away.\n",
            " |      - [callable] : a user-defined function which accepts an\n",
            " |        array of distances, and returns an array of the same shape\n",
            " |        containing the weights.\n",
            " |  \n",
            " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
            " |      Algorithm used to compute the nearest neighbors:\n",
            " |  \n",
            " |      - 'ball_tree' will use :class:`BallTree`\n",
            " |      - 'kd_tree' will use :class:`KDTree`\n",
            " |      - 'brute' will use a brute-force search.\n",
            " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
            " |        based on the values passed to :meth:`fit` method.\n",
            " |  \n",
            " |      Note: fitting on sparse input will override the setting of\n",
            " |      this parameter, using brute force.\n",
            " |  \n",
            " |  leaf_size : int, default=30\n",
            " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
            " |      speed of the construction and query, as well as the memory\n",
            " |      required to store the tree.  The optimal value depends on the\n",
            " |      nature of the problem.\n",
            " |  \n",
            " |  p : int, default=2\n",
            " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
            " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
            " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
            " |  \n",
            " |  metric : str or callable, default='minkowski'\n",
            " |      The distance metric to use for the tree.  The default metric is\n",
            " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
            " |      metric. For a list of available metrics, see the documentation of\n",
            " |      :class:`~sklearn.metrics.DistanceMetric`.\n",
            " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
            " |      must be square during fit. X may be a :term:`sparse graph`,\n",
            " |      in which case only \"nonzero\" elements may be considered neighbors.\n",
            " |  \n",
            " |  metric_params : dict, default=None\n",
            " |      Additional keyword arguments for the metric function.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      The number of parallel jobs to run for neighbors search.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |      Doesn't affect :meth:`fit` method.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  classes_ : array of shape (n_classes,)\n",
            " |      Class labels known to the classifier\n",
            " |  \n",
            " |  effective_metric_ : str or callble\n",
            " |      The distance metric used. It will be same as the `metric` parameter\n",
            " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
            " |      'minkowski' and `p` parameter set to 2.\n",
            " |  \n",
            " |  effective_metric_params_ : dict\n",
            " |      Additional keyword arguments for the metric function. For most metrics\n",
            " |      will be same with `metric_params` parameter, but may also contain the\n",
            " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
            " |      'minkowski'.\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_samples_fit_ : int\n",
            " |      Number of samples in the fitted data.\n",
            " |  \n",
            " |  outputs_2d_ : bool\n",
            " |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
            " |      otherwise True.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
            " |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
            " |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
            " |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
            " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
            " |  \n",
            " |  .. warning::\n",
            " |  \n",
            " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
            " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
            " |     but different labels, the results will depend on the ordering of the\n",
            " |     training data.\n",
            " |  \n",
            " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> X = [[0], [1], [2], [3]]\n",
            " |  >>> y = [0, 0, 1, 1]\n",
            " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
            " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
            " |  >>> neigh.fit(X, y)\n",
            " |  KNeighborsClassifier(...)\n",
            " |  >>> print(neigh.predict([[1.1]]))\n",
            " |  [0]\n",
            " |  >>> print(neigh.predict_proba([[0.9]]))\n",
            " |  [[0.666... 0.333...]]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      KNeighborsClassifier\n",
            " |      sklearn.neighbors._base.KNeighborsMixin\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      sklearn.neighbors._base.NeighborsBase\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y)\n",
            " |      Fit the k-nearest neighbors classifier from the training dataset.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
            " |          Training data.\n",
            " |      \n",
            " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
            " |          Target values.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : KNeighborsClassifier\n",
            " |          The fitted k-nearest neighbors classifier.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict the class labels for the provided data.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
            " |          Test samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
            " |          Class labels for each data sample.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Return probability estimates for the test data X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
            " |          Test samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n",
            " |          The class probabilities of the input samples. Classes are ordered\n",
            " |          by lexicographic order.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
            " |  \n",
            " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
            " |      Find the K-neighbors of a point.\n",
            " |      \n",
            " |      Returns indices of and distances to the neighbors of each point.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
            " |          The query point or points.\n",
            " |          If not provided, neighbors of each indexed point are returned.\n",
            " |          In this case, the query point is not considered its own neighbor.\n",
            " |      \n",
            " |      n_neighbors : int, default=None\n",
            " |          Number of neighbors required for each sample. The default is the\n",
            " |          value passed to the constructor.\n",
            " |      \n",
            " |      return_distance : bool, default=True\n",
            " |          Whether or not to return the distances.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
            " |          Array representing the lengths to points, only present if\n",
            " |          return_distance=True.\n",
            " |      \n",
            " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
            " |          Indices of the nearest points in the population matrix.\n",
            " |      \n",
            " |      Examples\n",
            " |      --------\n",
            " |      In the following example, we construct a NearestNeighbors\n",
            " |      class from an array representing our data set and ask who's\n",
            " |      the closest point to [1,1,1]\n",
            " |      \n",
            " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
            " |      >>> from sklearn.neighbors import NearestNeighbors\n",
            " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
            " |      >>> neigh.fit(samples)\n",
            " |      NearestNeighbors(n_neighbors=1)\n",
            " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
            " |      (array([[0.5]]), array([[2]]))\n",
            " |      \n",
            " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
            " |      element is at distance 0.5 and is the third element of samples\n",
            " |      (indexes start at 0). You can also query for multiple points:\n",
            " |      \n",
            " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
            " |      >>> neigh.kneighbors(X, return_distance=False)\n",
            " |      array([[1],\n",
            " |             [2]]...)\n",
            " |  \n",
            " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
            " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
            " |          The query point or points.\n",
            " |          If not provided, neighbors of each indexed point are returned.\n",
            " |          In this case, the query point is not considered its own neighbor.\n",
            " |          For ``metric='precomputed'`` the shape should be\n",
            " |          (n_queries, n_indexed). Otherwise the shape should be\n",
            " |          (n_queries, n_features).\n",
            " |      \n",
            " |      n_neighbors : int, default=None\n",
            " |          Number of neighbors for each sample. The default is the value\n",
            " |          passed to the constructor.\n",
            " |      \n",
            " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
            " |          Type of returned matrix: 'connectivity' will return the\n",
            " |          connectivity matrix with ones and zeros, in 'distance' the\n",
            " |          edges are distances between points, type of distance\n",
            " |          depends on the selected metric parameter in\n",
            " |          NearestNeighbors class.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
            " |          `n_samples_fit` is the number of samples in the fitted data.\n",
            " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
            " |          The matrix is of CSR format.\n",
            " |      \n",
            " |      See Also\n",
            " |      --------\n",
            " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
            " |          of Neighbors for points in X.\n",
            " |      \n",
            " |      Examples\n",
            " |      --------\n",
            " |      >>> X = [[0], [3], [1]]\n",
            " |      >>> from sklearn.neighbors import NearestNeighbors\n",
            " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
            " |      >>> neigh.fit(X)\n",
            " |      NearestNeighbors(n_neighbors=2)\n",
            " |      >>> A = neigh.kneighbors_graph(X)\n",
            " |      >>> A.toarray()\n",
            " |      array([[1., 0., 1.],\n",
            " |             [0., 1., 1.],\n",
            " |             [1., 0., 1.]])\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following code to generate an artificial dataset which contain three classes. Conduct a similar KNN analysis to the dataset and report your accuracy. "
      ],
      "metadata": {
        "id": "tws-xX2F5WH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "centers = [[2, 4], [6, 6], [1, 9]]\n",
        "n_classes = len(centers)\n",
        "data, labels = make_blobs(n_samples=150, \n",
        "                          centers=np.array(centers),\n",
        "                          random_state=1)\n",
        "# do a 80-20 split of the data\n",
        "res = train_test_split(data, labels, \n",
        "                       train_size=0.8,\n",
        "                       test_size=0.2,\n",
        "                       random_state=12)\n",
        "train_data, test_data, train_labels, test_labels = res\n",
        "\n",
        "# perform a KNN analysis of the simulated data\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train_data, train_labels)\n",
        "\n",
        "print(\"Predictions from the classifier:\")\n",
        "learn_data_predicted = knn.predict(train_data)\n",
        "print(learn_data_predicted)\n",
        "print(\"Target values:\")\n",
        "print(train_labels)\n",
        "print(accuracy_score(learn_data_predicted, train_labels))\n",
        "# output accuracy score\n",
        "knn2 = KNeighborsClassifier(algorithm='auto', \n",
        "                            leaf_size=30, \n",
        "                            metric='minkowski',\n",
        "                            p=2,         # p=2 is equivalent to euclidian distance\n",
        "                            metric_params=None, \n",
        "                            n_jobs=1, \n",
        "                            n_neighbors=5, \n",
        "                            weights='uniform')\n",
        "\n",
        "knn.fit(train_data, train_labels) \n",
        "test_data_predicted = knn.predict(test_data)\n",
        "accuracy_score(test_data_predicted, test_labels)\n",
        "# plot your different results\n",
        "plt.plot(learn_data_predicted,train_labels)\n"
      ],
      "metadata": {
        "id": "TwdApZEQwTz9",
        "outputId": "c5d1fe30-1e6a-46df-b0d1-d90ac2ac2221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions from the classifier:\n",
            "[0 2 1 0 0 1 1 2 2 0 2 2 2 1 1 0 0 2 1 1 0 0 0 1 1 2 0 0 1 0 1 1 1 0 1 2 0\n",
            " 1 0 1 2 2 2 0 2 0 2 2 0 0 0 1 2 2 2 2 1 1 0 1 2 1 2 2 2 0 0 0 0 0 0 0 1 1\n",
            " 2 1 2 1 2 2 1 1 1 0 2 1 2 1 0 1 2 1 0 2 0 1 2 2 0 2 1 0 0 2 1 1 2 2 0 1 1\n",
            " 1 2 2 2 1 1 2 1 2]\n",
            "Target values:\n",
            "[0 2 1 0 0 1 1 2 2 0 2 2 2 1 1 0 0 2 1 1 0 0 0 1 1 2 0 0 1 0 1 1 1 0 1 2 0\n",
            " 1 0 1 2 2 2 0 2 0 2 2 0 0 0 1 2 2 2 2 1 1 0 1 2 1 2 2 2 0 0 0 0 0 0 0 1 1\n",
            " 2 1 2 1 2 2 1 1 1 0 2 1 2 1 0 1 2 1 0 2 0 1 2 2 0 2 1 0 0 2 1 1 2 2 0 1 1\n",
            " 1 2 2 2 1 1 2 1 2]\n",
            "1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fdd3e265430>]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}